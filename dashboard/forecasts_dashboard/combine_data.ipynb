{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a7f87ed",
   "metadata": {},
   "source": [
    "# Sarimax Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cebe1442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d287220b",
   "metadata": {},
   "source": [
    "### 1) LOAD TRAFFIC COUNTER DATA, KEEP ONLY “Kfz” (all motor vehicles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6818eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic = pd.read_csv(\"../data/dauerzaehlstellen_data.csv\", parse_dates=[\"DATUM\"])\n",
    "traffic = (\n",
    "    traffic\n",
    "    .query('FZTYP==\"Kfz\" and RINAME==\"Gesamt\"')\n",
    "    .rename(columns={\"DATUM\":\"DATE\"})[[\"ZNR\",\"DATE\",\"DTVMS\",\"ISTCOVID19\"]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec46ce4e",
   "metadata": {},
   "source": [
    "### 2) LOAD LOCATION FILE TO GET DISTRICT_CODE FOR EACH ZNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "294450c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = pd.read_csv(\"../data/dauerzaehlstellen_location.csv\")\n",
    "loc = loc.rename(columns={\"BEZIRK_PLZ\":\"BEZIRK\"})[[\"ZNR\",\"BEZIRK\"]]\n",
    "traffic = traffic.merge(loc, on=\"ZNR\", how=\"left\")\n",
    "traffic = traffic[traffic[\"ZNR\"] != 1185]  # drop bad counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acee04c",
   "metadata": {},
   "source": [
    "\n",
    "### 3) LOAD EXOGENOUS DATASETS (all monthly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a295c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ausp = pd.read_csv(\"data_arima_final/auspendler_by_bezirk.csv\", parse_dates=[\"DATE\"])\n",
    "ausp[\"AUSPENDLER\"] = ausp[\"AUSPENDLER\"].astype(float)\n",
    "\n",
    "pop = pd.read_csv(\"data_arima_final/population_by_bezirk.csv\", parse_dates=[\"DATE\"])\n",
    "pop[\"POP\"] = pop[\"POP\"].astype(float)\n",
    "\n",
    "veh = pd.read_csv(\"data_arima_final/vehicle_density.csv\", parse_dates=[\"DATE\"])\n",
    "veh[\"PKW_DENSITY\"] = veh[\"PKW_DENSITY\"].astype(float)\n",
    "\n",
    "vmw = pd.read_csv(\"data_arima_final/verkehrsmittelwahl.csv\", parse_dates=[\"DATE\"])\n",
    "for col in [\"BICYCLE\",\"BIKESHARING\",\"BY_FOOT\",\"CAR\",\"CARSHARING\",\"MOTORBIKE\",\"PUBLIC_TRANSPORT\"]:\n",
    "    vmw[col] = vmw[col].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3dd67e",
   "metadata": {},
   "source": [
    "### 4) BUILD FULL PANEL UNTIL 2030"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a80e0397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the full panel (ZNR × every month from first traffic → Dec 2030)\n",
    "znrs      = traffic[\"ZNR\"].unique()\n",
    "start     = traffic[\"DATE\"].min().to_period(\"M\").to_timestamp()\n",
    "end       = pd.to_datetime(\"2030-12-01\")\n",
    "all_months= pd.date_range(start, end, freq=\"MS\")\n",
    "\n",
    "panel = (\n",
    "    pd.MultiIndex\n",
    "      .from_product([znrs, all_months], names=[\"ZNR\",\"DATE\"])\n",
    "      .to_frame(index=False)\n",
    ")\n",
    "\n",
    "# Merge in the observed counts & BEZIRK\n",
    "panel = panel.merge(traffic, on=[\"ZNR\",\"DATE\"], how=\"left\")\n",
    "\n",
    "# propagate each ZNR’s BEZIRK into all its months\n",
    "panel[\"BEZIRK\"] = (\n",
    "    panel\n",
    "    .groupby(\"ZNR\")[\"BEZIRK\"]\n",
    "    .transform(lambda s: s.ffill().bfill())\n",
    ")\n",
    "\n",
    "# mark all non‐observed months as no‐COVID\n",
    "panel[\"ISTCOVID19\"] = panel[\"ISTCOVID19\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ee332f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZNR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>DTVMS</th>\n",
       "      <th>ISTCOVID19</th>\n",
       "      <th>BEZIRK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11158</th>\n",
       "      <td>1197</td>\n",
       "      <td>2030-11-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11159</th>\n",
       "      <td>1197</td>\n",
       "      <td>2030-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1220.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ZNR       DATE  DTVMS  ISTCOVID19  BEZIRK\n",
       "11158  1197 2030-11-01    NaN         0.0  1220.0\n",
       "11159  1197 2030-12-01    NaN         0.0  1220.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panel.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ac6547",
   "metadata": {},
   "source": [
    "### 4) MERGE TRAFFIC + EXOGENOUS ON [DATE, BEZIRK] (AND DATE for vmw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9e517cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now merge all exogenous variables\n",
    "panel = panel.merge(ausp, on=[\"DATE\",\"BEZIRK\"], how=\"left\")\n",
    "panel = panel.merge(pop,  on=[\"DATE\",\"BEZIRK\"], how=\"left\")\n",
    "panel = panel.merge(veh[[\"DATE\",\"BEZIRK\",\"PKW_DENSITY\"]], on=[\"DATE\",\"BEZIRK\"], how=\"left\")\n",
    "panel = panel.merge(vmw, on=\"DATE\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a1f8616",
   "metadata": {},
   "outputs": [],
   "source": [
    "panel = panel.sort_values([\"ZNR\",\"DATE\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04245f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZNR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>DTVMS</th>\n",
       "      <th>ISTCOVID19</th>\n",
       "      <th>BEZIRK</th>\n",
       "      <th>AUSPENDLER</th>\n",
       "      <th>POP</th>\n",
       "      <th>PKW_DENSITY</th>\n",
       "      <th>BICYCLE</th>\n",
       "      <th>BIKESHARING</th>\n",
       "      <th>BY_FOOT</th>\n",
       "      <th>CAR</th>\n",
       "      <th>CARSHARING</th>\n",
       "      <th>MOTORBIKE</th>\n",
       "      <th>PUBLIC_TRANSPORT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1075</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>33645.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>0.105</td>\n",
       "      <td>180272.0</td>\n",
       "      <td>433.11</td>\n",
       "      <td>0.069791</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.270189</td>\n",
       "      <td>0.269192</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>0.384845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1075</td>\n",
       "      <td>2016-02-01</td>\n",
       "      <td>36981.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>0.105</td>\n",
       "      <td>180272.0</td>\n",
       "      <td>433.11</td>\n",
       "      <td>0.069791</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.270189</td>\n",
       "      <td>0.269192</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>0.384845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1075</td>\n",
       "      <td>2016-03-01</td>\n",
       "      <td>39057.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>0.105</td>\n",
       "      <td>180272.0</td>\n",
       "      <td>433.11</td>\n",
       "      <td>0.069791</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.270189</td>\n",
       "      <td>0.269192</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>0.384845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1075</td>\n",
       "      <td>2016-04-01</td>\n",
       "      <td>41570.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>0.105</td>\n",
       "      <td>180272.0</td>\n",
       "      <td>433.11</td>\n",
       "      <td>0.069791</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.270189</td>\n",
       "      <td>0.269192</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>0.384845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1075</td>\n",
       "      <td>2016-05-01</td>\n",
       "      <td>37195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>0.105</td>\n",
       "      <td>180272.0</td>\n",
       "      <td>433.11</td>\n",
       "      <td>0.069791</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>0.270189</td>\n",
       "      <td>0.269192</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>0.384845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ZNR       DATE    DTVMS  ISTCOVID19  BEZIRK  AUSPENDLER       POP  \\\n",
       "0  1075 2016-01-01  33645.0         0.0  1220.0       0.105  180272.0   \n",
       "1  1075 2016-02-01  36981.0         0.0  1220.0       0.105  180272.0   \n",
       "2  1075 2016-03-01  39057.0         0.0  1220.0       0.105  180272.0   \n",
       "3  1075 2016-04-01  41570.0         0.0  1220.0       0.105  180272.0   \n",
       "4  1075 2016-05-01  37195.0         0.0  1220.0       0.105  180272.0   \n",
       "\n",
       "   PKW_DENSITY   BICYCLE  BIKESHARING   BY_FOOT       CAR  CARSHARING  \\\n",
       "0       433.11  0.069791     0.000997  0.270189  0.269192    0.001994   \n",
       "1       433.11  0.069791     0.000997  0.270189  0.269192    0.001994   \n",
       "2       433.11  0.069791     0.000997  0.270189  0.269192    0.001994   \n",
       "3       433.11  0.069791     0.000997  0.270189  0.269192    0.001994   \n",
       "4       433.11  0.069791     0.000997  0.270189  0.269192    0.001994   \n",
       "\n",
       "   MOTORBIKE  PUBLIC_TRANSPORT  \n",
       "0   0.002991          0.384845  \n",
       "1   0.002991          0.384845  \n",
       "2   0.002991          0.384845  \n",
       "3   0.002991          0.384845  \n",
       "4   0.002991          0.384845  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panel.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aae6e75",
   "metadata": {},
   "source": [
    "### 5) CHECK MISSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96bdeb0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expecting 62×180 = 11160 rows\n",
      "Panel rows: 11160\n"
     ]
    }
   ],
   "source": [
    "# number of ZNR × number of months expected\n",
    "n_z = len(znrs)\n",
    "n_m = len(all_months)\n",
    "print(f\"Expecting {n_z}×{n_m} = {n_z * n_m} rows\")\n",
    "\n",
    "# actual\n",
    "print(\"Panel rows:\", len(panel))\n",
    "\n",
    "# should be equal\n",
    "assert len(panel) == n_z * n_m, \"⚠️ panel is missing some (ZNR,DATE) combinations!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d36812f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing BEZIRK: 0\n",
      "Missing ISTCOVID19: 0\n"
     ]
    }
   ],
   "source": [
    "# any missing district codes?\n",
    "print(\"Missing BEZIRK:\", panel[\"BEZIRK\"].isna().sum())\n",
    "\n",
    "# any missing covid dummy?\n",
    "print(\"Missing ISTCOVID19:\", panel[\"ISTCOVID19\"].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b72eb92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per exog column:\n",
      " AUSPENDLER          0\n",
      "POP                 0\n",
      "PKW_DENSITY         0\n",
      "BICYCLE             0\n",
      "BIKESHARING         0\n",
      "BY_FOOT             0\n",
      "CAR                 0\n",
      "CARSHARING          0\n",
      "MOTORBIKE           0\n",
      "PUBLIC_TRANSPORT    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# list all exog columns\n",
    "exog_cols = [\"AUSPENDLER\",\"POP\",\"PKW_DENSITY\"] + \\\n",
    "            [\"BICYCLE\",\"BIKESHARING\",\"BY_FOOT\",\"CAR\",\"CARSHARING\",\"MOTORBIKE\",\"PUBLIC_TRANSPORT\"]\n",
    "\n",
    "miss = panel[exog_cols].isna().sum()\n",
    "print(\"Missing values per exog column:\\n\", miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fcbda2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     62.000000\n",
      "mean     103.258065\n",
      "std       11.192702\n",
      "min       63.000000\n",
      "25%      108.000000\n",
      "50%      108.000000\n",
      "75%      108.000000\n",
      "max      108.000000\n",
      "Name: DTVMS, dtype: float64\n",
      "Short histories: []\n"
     ]
    }
   ],
   "source": [
    "# for each counter, count how many observed months you actually have\n",
    "obs_counts = panel.groupby(\"ZNR\")[\"DTVMS\"].apply(lambda s: s.notna().sum())\n",
    "\n",
    "# expected obs span (e.g. if first obs per counter is 2016-01 to last obs 2024-12 → 108 months)\n",
    "print(obs_counts.describe())\n",
    "\n",
    "# counters with fewer than, say, 36 obs you might skip or treat specially\n",
    "print(\"Short histories:\", obs_counts[obs_counts < 36].index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae6e3072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     62.000000\n",
      "mean     103.258065\n",
      "std       11.192702\n",
      "min       63.000000\n",
      "25%      108.000000\n",
      "50%      108.000000\n",
      "75%      108.000000\n",
      "max      108.000000\n",
      "Name: DTVMS, dtype: float64\n",
      "Counters with < 36 months of history: []\n"
     ]
    }
   ],
   "source": [
    "# count non-NaN DTVMS per ZNR\n",
    "obs_counts = panel.groupby(\"ZNR\")[\"DTVMS\"].apply(lambda s: s.notna().sum())\n",
    "\n",
    "print(obs_counts.describe())\n",
    "print(\"Counters with < 36 months of history:\", obs_counts[obs_counts<36].index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3247391b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ZNR  first_obs  months_expected  months_missing  full_history\n",
      "0   1075 2016-01-01              108               0          True\n",
      "1   1078 2016-01-01              108               0          True\n",
      "2   1089 2016-01-01              108               0          True\n",
      "3   1096 2016-01-01              108               0          True\n",
      "4   1131 2016-01-01              108               0          True\n",
      "..   ...        ...              ...             ...           ...\n",
      "57  1623 2016-01-01              108               0          True\n",
      "58  1624 2016-01-01              108               0          True\n",
      "59  1625 2018-01-01               84               0          True\n",
      "60  1626 2018-01-01               84               0          True\n",
      "61  1627 2018-01-01               84               0          True\n",
      "\n",
      "[62 rows x 5 columns]\n",
      "Counters with no gaps: [1075, 1078, 1089, 1096, 1131, 1170, 1177, 1179, 1180, 1181, 1182, 1184, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1198, 1200, 1201, 1202, 1205, 1206, 1207, 1208, 1209, 1211, 1212, 1215, 1216, 1217, 1218, 1220, 1221, 1223, 1224, 1603, 1608, 1611, 1612, 1613, 1614, 1616, 1617, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627]\n",
      "Counters with gaps:\n",
      "      ZNR  first_obs  months_expected  months_missing  full_history\n",
      "22  1197 2016-01-01              108              12         False\n",
      "24  1199 2016-01-01              108               1         False\n",
      "39  1219 2018-04-01               81               1         False\n",
      "52  1618 2016-01-01              108               4         False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# assume `panel` is your DataFrame with columns [\"ZNR\",\"DATE\",\"DTVMS\",…]\n",
    "# and DATE is a datetime64 column\n",
    "\n",
    "def check_full_history(df, end_date=\"2024-12-01\"):\n",
    "    first_obs = df.loc[df[\"DTVMS\"].notna(), \"DATE\"].min()\n",
    "    if pd.isna(first_obs):\n",
    "        return False, None, None, None\n",
    "    # build the expected monthly dates\n",
    "    expected = pd.date_range(first_obs, end_date, freq=\"MS\")\n",
    "    # actual months where DTVMS is observed\n",
    "    actual   = df.loc[df[\"DTVMS\"].notna(), \"DATE\"].drop_duplicates().sort_values()\n",
    "    # count how many of the expected appear in actual\n",
    "    n_expected = len(expected)\n",
    "    n_actual   = actual.isin(expected).sum()\n",
    "    missing    = n_expected - n_actual\n",
    "    return missing == 0, first_obs, n_expected, missing\n",
    "\n",
    "# apply per counter\n",
    "results = []\n",
    "for znr, grp in panel.groupby(\"ZNR\"):\n",
    "    complete, first, total_mons, n_missing = check_full_history(grp, \"2024-12-01\")\n",
    "    results.append({\n",
    "        \"ZNR\": znr,\n",
    "        \"first_obs\": first,\n",
    "        \"months_expected\": total_mons,\n",
    "        \"months_missing\": n_missing,\n",
    "        \"full_history\": complete\n",
    "    })\n",
    "\n",
    "check_df = pd.DataFrame(results)\n",
    "print(check_df)\n",
    "\n",
    "# List counters with a perfect history:\n",
    "perfect = check_df[check_df[\"full_history\"]][\"ZNR\"].tolist()\n",
    "print(\"Counters with no gaps:\", perfect)\n",
    "\n",
    "# List counters with any gaps:\n",
    "gappy = check_df[check_df[\"months_missing\"]>0]\n",
    "print(\"Counters with gaps:\\n\", gappy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63d1d6db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ZNR  first_obs  months_expected  months_missing  full_history\n",
      "0   1075 2016-01-01              108               0          True\n",
      "1   1078 2016-01-01              108               0          True\n",
      "2   1089 2016-01-01              108               0          True\n",
      "3   1096 2016-01-01              108               0          True\n",
      "4   1131 2016-01-01              108               0          True\n",
      "..   ...        ...              ...             ...           ...\n",
      "57  1623 2016-01-01              108               0          True\n",
      "58  1624 2016-01-01              108               0          True\n",
      "59  1625 2018-01-01               84               0          True\n",
      "60  1626 2018-01-01               84               0          True\n",
      "61  1627 2018-01-01               84               0          True\n",
      "\n",
      "[62 rows x 5 columns]\n",
      "Counters with no gaps: [1075, 1078, 1089, 1096, 1131, 1170, 1177, 1179, 1180, 1181, 1182, 1184, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1198, 1200, 1201, 1202, 1205, 1206, 1207, 1208, 1209, 1211, 1212, 1215, 1216, 1217, 1218, 1220, 1221, 1223, 1224, 1603, 1608, 1611, 1612, 1613, 1614, 1616, 1617, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627]\n",
      "Counters with gaps:\n",
      "      ZNR  first_obs  months_expected  months_missing  full_history\n",
      "22  1197 2016-01-01              108              12         False\n",
      "24  1199 2016-01-01              108               1         False\n",
      "39  1219 2018-04-01               81               1         False\n",
      "52  1618 2016-01-01              108               4         False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# assume `panel` is your DataFrame with columns [\"ZNR\",\"DATE\",\"DTVMS\",…]\n",
    "# and DATE is a datetime64 column\n",
    "\n",
    "def check_full_history(df, end_date=\"2024-12-01\"):\n",
    "    obs = df[\"DTVMS\"] > 0\n",
    "    first_obs = df.loc[obs, \"DATE\"].min()\n",
    "    expected  = pd.date_range(first_obs, end_date, freq=\"MS\")\n",
    "    actual    = df.loc[obs, \"DATE\"].drop_duplicates().sort_values()\n",
    "    n_expected = len(expected)\n",
    "    n_actual   = actual.isin(expected).sum()\n",
    "    missing    = n_expected - n_actual\n",
    "    return missing == 0, first_obs, n_expected, missing\n",
    "\n",
    "# apply per counter\n",
    "results = []\n",
    "for znr, grp in panel.groupby(\"ZNR\"):\n",
    "    complete, first, total_mons, n_missing = check_full_history(grp, \"2024-12-01\")\n",
    "    results.append({\n",
    "        \"ZNR\": znr,\n",
    "        \"first_obs\": first,\n",
    "        \"months_expected\": total_mons,\n",
    "        \"months_missing\": n_missing,\n",
    "        \"full_history\": complete\n",
    "    })\n",
    "\n",
    "check_df = pd.DataFrame(results)\n",
    "print(check_df)\n",
    "\n",
    "# List counters with a perfect history:\n",
    "perfect = check_df[check_df[\"full_history\"]][\"ZNR\"].tolist()\n",
    "print(\"Counters with no gaps:\", perfect)\n",
    "\n",
    "# List counters with any gaps:\n",
    "gappy = check_df[check_df[\"months_missing\"]>0]\n",
    "print(\"Counters with gaps:\\n\", gappy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc2fca03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ZNR  months_missing_after\n",
      "23  1199                     0\n",
      "38  1219                     0\n",
      "51  1618                     0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mihim\\AppData\\Local\\Temp\\ipykernel_143416\\2901769923.py:39: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  gap_check = panel.groupby(\"ZNR\").apply(count_missing).reset_index(name=\"months_missing_after\")\n"
     ]
    }
   ],
   "source": [
    "# 1) Drop the counter with too many gaps\n",
    "panel = panel[panel[\"ZNR\"] != 1197].copy()\n",
    "\n",
    "# 2) List of counters to impute\n",
    "to_impute = [1199, 1219, 1618]\n",
    "\n",
    "# 3) Impute each one on its historical window (up to 2024-12-01)\n",
    "for znr in to_impute:\n",
    "    # boolean masks\n",
    "    mask_znr  = panel[\"ZNR\"] == znr\n",
    "    mask_hist = panel[\"DATE\"] <= pd.to_datetime(\"2024-12-01\")\n",
    "    mask      = mask_znr & mask_hist\n",
    "\n",
    "    # extract and index by DATE\n",
    "    tmp = (panel.loc[mask, [\"DATE\", \"DTVMS\"]]\n",
    "              .set_index(\"DATE\")\n",
    "              .sort_index()\n",
    "              .copy())\n",
    "\n",
    "    # interpolate only inside known values\n",
    "    tmp[\"DTVMS\"] = tmp[\"DTVMS\"].interpolate(\n",
    "        method=\"time\",\n",
    "        limit_area=\"inside\"\n",
    "    )\n",
    "\n",
    "    # forward/back-fill any head/tail NaNs\n",
    "    tmp[\"DTVMS\"] = tmp[\"DTVMS\"].ffill().bfill()\n",
    "\n",
    "    # write back into the main panel\n",
    "    panel.loc[mask, \"DTVMS\"] = tmp[\"DTVMS\"].values\n",
    "\n",
    "# 4) (Optional) Verify that no gaps remain in history\n",
    "def count_missing(grp):\n",
    "    first = grp[\"DATE\"].min()\n",
    "    expected = pd.date_range(first, \"2024-12-01\", freq=\"MS\")\n",
    "    actual   = grp.loc[grp[\"DTVMS\"] > 0, \"DATE\"].drop_duplicates().sort_values()\n",
    "    return len(expected) - actual.isin(expected).sum()\n",
    "\n",
    "gap_check = panel.groupby(\"ZNR\").apply(count_missing).reset_index(name=\"months_missing_after\")\n",
    "print(gap_check[gap_check[\"ZNR\"].isin(to_impute)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3101596",
   "metadata": {},
   "source": [
    "### 6) SAVE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4aa711d",
   "metadata": {},
   "outputs": [],
   "source": [
    "panel.to_csv(\"merged_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45db579f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"merged_df.csv\", parse_dates=[\"DATE\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
